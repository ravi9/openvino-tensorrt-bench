{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO benchmarking with 2D U-Net\n",
    "In this tutorial, we will use the Intel® Distribution of OpenVINO™ Toolkit to perform benchmarking\n",
    "\n",
    "This tutorial assumes that you have already downloaded and installed [Intel&reg; OpenVINO&trade;](https://software.intel.com/en-us/openvino-toolkit/choose-download) on your computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Intel® OpenVINO™, we need to do a few steps:\n",
    "\n",
    "1. Convert our Keras model to a Tensorflow model. \n",
    "1. Freeze the Tensorflow saved format model\n",
    "1. Use the OpenVINO Model Optimizer to convert the above freezed-model to the OpenVINO Intermediate Representation (IR) format\n",
    "1. Benchmark using the OpenVINO benchmark tool: `/opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras as K\n",
    "import shutil, sys  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, axis=(1, 2), smooth=1):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice\n",
    "    \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "    where T is ground truth mask and P is the prediction mask\n",
    "    \"\"\"\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=axis)\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=axis)\n",
    "    numerator = tf.constant(2.) * intersection + smooth\n",
    "    denominator = union + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return tf.reduce_mean(coef)\n",
    "\n",
    "def soft_dice_coef(target, prediction, axis=(1, 2), smooth=0.01):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice  - Don't round the predictions\n",
    "    \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "    where T is ground truth mask and P is the prediction mask\n",
    "    \"\"\"\n",
    "\n",
    "    intersection = tf.reduce_sum(target * prediction, axis=axis)\n",
    "    union = tf.reduce_sum(target + prediction, axis=axis)\n",
    "    numerator = tf.constant(2.) * intersection + smooth\n",
    "    denominator = union + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return tf.reduce_mean(coef)\n",
    "\n",
    "def dice_coef_loss(target, prediction, axis=(1, 2), smooth=1.):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice loss\n",
    "    Using -log(Dice) as the loss since it is better behaved.\n",
    "    Also, the log allows avoidance of the division which\n",
    "    can help prevent underflow when the numbers are very small.\n",
    "    \"\"\"\n",
    "    intersection = tf.reduce_sum(prediction * target, axis=axis)\n",
    "    p = tf.reduce_sum(prediction, axis=axis)\n",
    "    t = tf.reduce_sum(target, axis=axis)\n",
    "    numerator = tf.reduce_mean(intersection + smooth)\n",
    "    denominator = tf.reduce_mean(t + p + smooth)\n",
    "    dice_loss = -tf.log(2.*numerator) + tf.log(denominator)\n",
    "\n",
    "    return dice_loss\n",
    "\n",
    "\n",
    "def combined_dice_ce_loss(y_true, y_pred, axis=(1, 2), smooth=1.,\n",
    "                          weight=0.9):\n",
    "    \"\"\"\n",
    "    Combined Dice and Binary Cross Entropy Loss\n",
    "    \"\"\"\n",
    "    return weight*dice_coef_loss(y_true, y_pred, axis, smooth) + \\\n",
    "        (1-weight)*K.losses.binary_crossentropy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model... \n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2020: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model loaded successfully from: /home/ubuntu/models/unet/unet_decathlon_4_8814_128x128_randomcrop-any-input.h5\n"
     ]
    }
   ],
   "source": [
    "inference_filename = \"unet_decathlon_4_8814_128x128_randomcrop-any-input.h5\"\n",
    "model_filename = os.path.join(\"/home/ubuntu/models/unet\", inference_filename)\n",
    "\n",
    "# Load model\n",
    "print(\"Loading Model... \")\n",
    "model = K.models.load_model(model_filename, custom_objects={\n",
    "    \"combined_dice_ce_loss\": combined_dice_ce_loss,\n",
    "    \"dice_coef_loss\": dice_coef_loss,\n",
    "    \"soft_dice_coef\": soft_dice_coef,\n",
    "    \"dice_coef\": dice_coef})\n",
    "print(\"Model loaded successfully from: \" + model_filename)\n",
    "\n",
    "sess = keras.backend.get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the graph.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ubuntu/models/unet/output/saved_model.pb\n",
      "TensorFlow protobuf version of model is saved in: /home/ubuntu/models/unet/output\n",
      "Model input name =  MRImages\n",
      "Model input shape =  (?, ?, ?, 4)\n",
      "Model output name =  PredictionMask/Sigmoid\n",
      "Model output shape =  (?, ?, ?, 1)\n"
     ]
    }
   ],
   "source": [
    "import shutil, sys   \n",
    "\n",
    "output_directory = \"/home/ubuntu/models/unet/output\"\n",
    "print(\"Freezing the graph.\")\n",
    "keras.backend.set_learning_phase(0)\n",
    "\n",
    "signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input': model.input}, outputs={'output': model.output})\n",
    "\n",
    "#If directory exists, delete it and let builder rebuild the TF model.\n",
    "if os.path.isdir(output_directory):\n",
    "    print (output_directory, \"exists already. Deleting the folder\")\n",
    "    shutil.rmtree(output_directory)\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(output_directory)\n",
    "builder.add_meta_graph_and_variables(sess=sess,    \n",
    "                                     tags=[tf.saved_model.tag_constants.SERVING],    \n",
    "                                     signature_def_map={\n",
    "                                         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature\n",
    "                                     }, saver=tf.train.Saver())\n",
    "builder.save() \n",
    "print(\"TensorFlow protobuf version of model is saved in:\", output_directory)\n",
    "\n",
    "print(\"Model input name = \", model.input.op.name)\n",
    "print(\"Model input shape = \", model.input.shape)\n",
    "print(\"Model output name = \", model.output.op.name)\n",
    "print(\"Model output shape = \", model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:161: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/output/variables/variables\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 38 variables.\n",
      "INFO:tensorflow:Converted 38 variables to const ops.\n",
      "TensorFlow Frozen model model is saved in: /home/ubuntu/models/unet/frozen_model/saved_model_frozen.pb\n"
     ]
    }
   ],
   "source": [
    "output_frozen_model_dir = \"/home/ubuntu/models/unet/frozen_model\"\n",
    "output_frozen_graph = output_frozen_model_dir+'/saved_model_frozen.pb'\n",
    "\n",
    "if not os.path.isdir(output_frozen_model_dir):\n",
    "    os.mkdir(output_frozen_model_dir)\n",
    "else:\n",
    "    print('Directory', output_frozen_model_dir, 'already exists. Deleting it and re-creating it')\n",
    "    shutil.rmtree(output_frozen_model_dir)\n",
    "    os.mkdir(output_frozen_model_dir)\n",
    "\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "\n",
    "_ = freeze_graph(input_graph=\"\",\n",
    "             input_saver=\"\",\n",
    "             input_binary=False,\n",
    "             input_checkpoint=\"\",\n",
    "             restore_op_name=\"save/restore_all\",\n",
    "             filename_tensor_name=\"save/Const:0\",\n",
    "             clear_devices=True,\n",
    "             initializer_nodes=\"\",\n",
    "             input_saved_model_dir=output_directory,\n",
    "             output_node_names=model.output.op.name,\n",
    "             output_graph=output_frozen_graph)\n",
    "\n",
    "print(\"TensorFlow Frozen model model is saved in:\", output_frozen_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_frozen_model_dir = \"/home/ubuntu/models/unet/frozen_model\"\n",
    "output_frozen_graph = output_frozen_model_dir+'/saved_model_frozen.pb'\n",
    "\n",
    "if not os.path.exists(output_frozen_graph):\n",
    "    print(output_frozen_graph + ' doesn\\'t exist. Please make sure you have a trained keras to TF frozen model')\n",
    "\n",
    "!mo_tf.py \\\n",
    "      --input_model '/home/ubuntu/models/unet/frozen_model/saved_model_frozen.pb' \\\n",
    "      --input_shape=[1,160,160,4] \\\n",
    "      --data_type FP32  \\\n",
    "      --output_dir /home/ubuntu/models/unet/IR_models/FP32  \\\n",
    "      --model_name saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following command in the terminal\n",
    "```\n",
    "mo_tf.py \\\n",
    "      --input_model '/home/ubuntu/models/unet/frozen_model/saved_model_frozen.pb' \\\n",
    "      --input_shape=[1,160,160,4] \\\n",
    "      --data_type FP32  \\\n",
    "      --output_dir /home/ubuntu/models/unet/IR_models/FP32  \\\n",
    "      --model_name saved_model\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Output: \n",
    "```\n",
    "(tensorflow_p36) ubuntu@ip-172-31-46-30:~$ mo_tf.py \\\n",
    ">       --input_model '/home/ubuntu/models/unet/frozen_model/saved_model_frozen.pb' \\\n",
    ">       --input_shape=[1,160,160,4] \\\n",
    ">       --data_type FP32  \\\n",
    ">       --output_dir /home/ubuntu/models/unet/IR_models/FP32  \\\n",
    ">       --model_name saved_model\n",
    "Model Optimizer arguments:\n",
    "Common parameters:\n",
    "        - Path to the Input Model:      /home/ubuntu/models/unet/frozen_model/saved_model_frozen.pb\n",
    "        - Path for generated IR:        /home/ubuntu/models/unet/IR_models/FP32\n",
    "        - IR output name:       saved_model\n",
    "        - Log level:    ERROR\n",
    "        - Batch:        Not specified, inherited from the model\n",
    "        - Input layers:         Not specified, inherited from the model\n",
    "        - Output layers:        Not specified, inherited from the model\n",
    "        - Input shapes:         [1,160,160,4]\n",
    "        - Mean values:  Not specified\n",
    "        - Scale values:         Not specified\n",
    "        - Scale factor:         Not specified\n",
    "        - Precision of IR:      FP32\n",
    "        - Enable fusing:        True\n",
    "        - Enable grouped convolutions fusing:   True\n",
    "        - Move mean values to preprocess section:       False\n",
    "        - Reverse input channels:       False\n",
    "TensorFlow specific parameters:\n",
    "        - Input model in text protobuf format:  False\n",
    "        - Path to model dump for TensorBoard:   None\n",
    "        - List of shared libraries with TensorFlow custom layers implementation:        None\n",
    "        - Update the configuration file with input/output node names:   None\n",
    "        - Use configuration file used to generate the model with Object Detection API:  None\n",
    "        - Operations to offload:        None\n",
    "        - Patterns to offload:  None\n",
    "        - Use the config file:  None\n",
    "Model Optimizer version:        2020.1.0-61-gd349c3ba4a\n",
    "\n",
    "[ SUCCESS ] Generated IR version 10 model.\n",
    "[ SUCCESS ] XML file: /home/ubuntu/models/unet/IR_models/FP32/saved_model.xml\n",
    "[ SUCCESS ] BIN file: /home/ubuntu/models/unet/IR_models/FP32/saved_model.bin\n",
    "[ SUCCESS ] Total execution time: 6.41 seconds.\n",
    "[ SUCCESS ] Memory consumed: 443 MB.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark using the following command:\n",
    "```\n",
    "python3 /opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py \\\n",
    "-m /home/ubuntu/models/unet/IR_models/FP32/saved_model.xml \\\n",
    "-nireq 1 -nstreams 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Output\n",
    "```\n",
    "[Step 1/11] Parsing and validating input arguments\n",
    "[Step 2/11] Loading Inference Engine\n",
    "[ INFO ] InferenceEngine:\n",
    "         API version............. 2.1.37988\n",
    "[ INFO ] Device info\n",
    "         CPU\n",
    "         MKLDNNPlugin............ version 2.1\n",
    "         Build................... 37988\n",
    "\n",
    "[Step 3/11] Reading the Intermediate Representation network\n",
    "[Step 4/11] Resizing network to match image sizes and given batch\n",
    "[ INFO ] Network batch size: 1, precision: MIXED\n",
    "[Step 5/11] Configuring input of the model\n",
    "[Step 6/11] Setting device configuration\n",
    "[Step 7/11] Loading the model to the device\n",
    "[Step 8/11] Setting optimal runtime parameters\n",
    "[Step 9/11] Creating infer requests and filling input blobs with images\n",
    "[ INFO ] Network input 'MRImages' precision FP32, dimensions (NCHW): 1 4 160 160\n",
    "[ WARNING ] No input files were given: all inputs will be filled with random values!\n",
    "[ INFO ] Infer Request 0 filling\n",
    "[ INFO ] Fill input 'MRImages' with random values (some binary data is expected)\n",
    "[Step 10/11] Measuring performance (Start inference asyncronously, 1 inference requests using 1 streams for CPU, limits: 60000 ms duration)\n",
    "[Step 11/11] Dumping statistics report\n",
    "Count:      11079 iterations\n",
    "Duration:   60014.36 ms\n",
    "Latency:    5.11 ms\n",
    "Throughput: 184.61 FPS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
