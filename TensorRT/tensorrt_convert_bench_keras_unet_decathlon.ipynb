{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT benchmarking with 2D U-Net\n",
    "In this tutorial, we will use the TensorRT to perform benchmarking on InceptionV3 model.\n",
    "\n",
    "This tutorial assumes that you running on [AWS Ubuntu DLAMI](https://aws.amazon.com/marketplace/pp/B07Y43P7X5). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are steps:\n",
    "\n",
    "1. Convert our Keras model to a Tensorflow model. \n",
    "1. Freeze the Tensorflow saved format model\n",
    "1. Convert the above freezed-model to the TensorRT formats: FP32 and FP16 (for V100)\n",
    "1. Benchmark with BZ=1, run the inference with BZ=1 for 1 min.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras as K\n",
    "import shutil, sys  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, axis=(1, 2), smooth=1):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice\n",
    "    \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "    where T is ground truth mask and P is the prediction mask\n",
    "    \"\"\"\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=axis)\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=axis)\n",
    "    numerator = tf.constant(2.) * intersection + smooth\n",
    "    denominator = union + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return tf.reduce_mean(coef)\n",
    "\n",
    "def soft_dice_coef(target, prediction, axis=(1, 2), smooth=0.01):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice  - Don't round the predictions\n",
    "    \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "    where T is ground truth mask and P is the prediction mask\n",
    "    \"\"\"\n",
    "\n",
    "    intersection = tf.reduce_sum(target * prediction, axis=axis)\n",
    "    union = tf.reduce_sum(target + prediction, axis=axis)\n",
    "    numerator = tf.constant(2.) * intersection + smooth\n",
    "    denominator = union + smooth\n",
    "    coef = numerator / denominator\n",
    "\n",
    "    return tf.reduce_mean(coef)\n",
    "\n",
    "def dice_coef_loss(target, prediction, axis=(1, 2), smooth=1.):\n",
    "    \"\"\"\n",
    "    Sorenson (Soft) Dice loss\n",
    "    Using -log(Dice) as the loss since it is better behaved.\n",
    "    Also, the log allows avoidance of the division which\n",
    "    can help prevent underflow when the numbers are very small.\n",
    "    \"\"\"\n",
    "    intersection = tf.reduce_sum(prediction * target, axis=axis)\n",
    "    p = tf.reduce_sum(prediction, axis=axis)\n",
    "    t = tf.reduce_sum(target, axis=axis)\n",
    "    numerator = tf.reduce_mean(intersection + smooth)\n",
    "    denominator = tf.reduce_mean(t + p + smooth)\n",
    "    dice_loss = -tf.log(2.*numerator) + tf.log(denominator)\n",
    "\n",
    "    return dice_loss\n",
    "\n",
    "\n",
    "def combined_dice_ce_loss(y_true, y_pred, axis=(1, 2), smooth=1.,\n",
    "                          weight=0.9):\n",
    "    \"\"\"\n",
    "    Combined Dice and Binary Cross Entropy Loss\n",
    "    \"\"\"\n",
    "    return weight*dice_coef_loss(y_true, y_pred, axis, smooth) + \\\n",
    "        (1-weight)*K.losses.binary_crossentropy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model... \n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2020: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model loaded successfully from: /home/ubuntu/models/unet/unet_decathlon_4_8814_128x128_randomcrop-any-input.h5\n"
     ]
    }
   ],
   "source": [
    "inference_filename = \"unet_decathlon_4_8814_128x128_randomcrop-any-input.h5\"\n",
    "model_filename = os.path.join(\"/home/ubuntu/models/unet\", inference_filename)\n",
    "\n",
    "# Load model\n",
    "print(\"Loading Model... \")\n",
    "model = K.models.load_model(model_filename, custom_objects={\n",
    "    \"combined_dice_ce_loss\": combined_dice_ce_loss,\n",
    "    \"dice_coef_loss\": dice_coef_loss,\n",
    "    \"soft_dice_coef\": soft_dice_coef,\n",
    "    \"dice_coef\": dice_coef})\n",
    "print(\"Model loaded successfully from: \" + model_filename)\n",
    "\n",
    "sess = keras.backend.get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the graph.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "/home/ubuntu/models/unet/output exists already. Deleting the folder\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ubuntu/models/unet/output/saved_model.pb\n",
      "TensorFlow protobuf version of model is saved in: /home/ubuntu/models/unet/output\n",
      "Model input name =  MRImages\n",
      "Model input shape =  (?, ?, ?, 4)\n",
      "Model output name =  PredictionMask/Sigmoid\n",
      "Model output shape =  (?, ?, ?, 1)\n"
     ]
    }
   ],
   "source": [
    "import shutil, sys   \n",
    "\n",
    "output_directory = \"/home/ubuntu/models/unet/output\"\n",
    "print(\"Freezing the graph.\")\n",
    "keras.backend.set_learning_phase(0)\n",
    "\n",
    "signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input': model.input}, outputs={'output': model.output})\n",
    "\n",
    "#If directory exists, delete it and let builder rebuild the TF model.\n",
    "if os.path.isdir(output_directory):\n",
    "    print (output_directory, \"exists already. Deleting the folder\")\n",
    "    shutil.rmtree(output_directory)\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(output_directory)\n",
    "builder.add_meta_graph_and_variables(sess=sess,    \n",
    "                                     tags=[tf.saved_model.tag_constants.SERVING],    \n",
    "                                     signature_def_map={\n",
    "                                         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature\n",
    "                                     }, saver=tf.train.Saver())\n",
    "builder.save() \n",
    "print(\"TensorFlow protobuf version of model is saved in:\", output_directory)\n",
    "\n",
    "print(\"Model input name = \", model.input.op.name)\n",
    "print(\"Model input shape = \", model.input.shape)\n",
    "print(\"Model output name = \", model.output.op.name)\n",
    "print(\"Model output shape = \", model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/models/unet/trt-output/ exists already. Deleting the folder\n",
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Running against TensorRT version 0.0.0\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py:494: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/output/variables/variables\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py:517: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 38 variables.\n",
      "INFO:tensorflow:Converted 38 variables to const ops.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ubuntu/models/unet/trt-output/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "input_saved_model_dir = output_directory\n",
    "output_saved_model_dir = \"/home/ubuntu/models/unet/trt-output/\"\n",
    "\n",
    "#If directory exists, delete it and let builder rebuild the TF model.\n",
    "if os.path.isdir(output_saved_model_dir):\n",
    "    print (output_saved_model_dir, \"exists already. Deleting the folder\")\n",
    "    shutil.rmtree(output_saved_model_dir)\n",
    "    \n",
    "converter = trt.TrtGraphConverter(\n",
    "    input_saved_model_dir=input_saved_model_dir,\n",
    "    precision_mode=\"FP32\",\n",
    "    maximum_cached_engines=100)\n",
    "\n",
    "_ = converter.convert()\n",
    "_ = converter.save(output_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the variables. As the frozen graph donot have any variables and it raises error while serving.\n",
    "!cp -pra /home/ubuntu/models/unet/output/variables/ /home/ubuntu/models/unet/trt-output/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/trt-output/variables/variables\n",
      "\n",
      "Model: /home/ubuntu/models/unet/trt-output/, Input shape: (1, 160, 160, 4) , Output shape: (1, 160, 160, 1) \n",
      "Completed Inference with one sample in 2.189 sec,\n"
     ]
    }
   ],
   "source": [
    "# Benchmark on one sample\n",
    "import time\n",
    "output_saved_model_dir = \"/home/ubuntu/models/unet/trt-output/\"\n",
    "output_tensor =  'PredictionMask/Sigmoid:0'\n",
    "input_tensor = 'MRImages:0'\n",
    "input_data = np.random.randint(0, 255, size=(1,160,160,4))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # First load the SavedModel into the session\n",
    "    tf.saved_model.loader.load(\n",
    "        sess, [tf.saved_model.tag_constants.SERVING],\n",
    "       output_saved_model_dir)\n",
    "    start_time = time.time()\n",
    "    output = sess.run([output_tensor], feed_dict={input_tensor: input_data})\n",
    "    delta = (time.time() - start_time)\n",
    "\n",
    "print(\"\\nModel: {}, Input shape: {} , Output shape: {} \\nCompleted Inference with one sample in {:.3f} sec,\"\n",
    "      .format(output_saved_model_dir, input_data.shape, output[0].shape, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_1min(output_saved_model_dir):\n",
    "    output_tensor =  'PredictionMask/Sigmoid:0'\n",
    "    input_tensor = 'MRImages:0'\n",
    "    input_data = np.random.randint(0, 255, size=(1,160,160,4))\n",
    "\n",
    "    tf_config = tf.ConfigProto()\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "    # First load the SavedModel into the session\n",
    "    tf.saved_model.loader.load(\n",
    "            tf_sess, [tf.saved_model.tag_constants.SERVING],\n",
    "           output_saved_model_dir)\n",
    "\n",
    "    tf_sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    import time\n",
    "    times = []\n",
    "    # Run inference for 1 min.\n",
    "    end = time.time() + 60\n",
    "    print(time.strftime(\"%H:%M:%S\"))\n",
    "    print(\"Running inference for 1 min, with BZ=1\")\n",
    "    print(\"Model: {}, Input shape: {}  \"\n",
    "          .format(output_saved_model_dir, input_data.shape))\n",
    "    while time.time() < end:\n",
    "        start_time = time.time()\n",
    "        output = tf_sess.run([output_tensor], feed_dict={input_tensor: input_data})\n",
    "        delta = (time.time() - start_time)\n",
    "        times.append(delta)\n",
    "\n",
    "    mean_delta = np.array(times).mean()\n",
    "    fps = 1 / mean_delta\n",
    "    print('Output Shape: {}, \\naverage(sec):{:.3f} , average(msec):{:.2f} , fps:{:.2f}'\n",
    "          .format(output[0].shape, mean_delta, mean_delta*1000, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/trt-output/variables/variables\n",
      "23:53:29\n",
      "Running inference for 1 min, with BZ=1\n",
      "Model: /home/ubuntu/models/unet/trt-output/, Input shape: (1, 160, 160, 4)  \n",
      "Output Shape: (1, 160, 160, 1), \n",
      "average(sec):0.007 , average(msec):7.15 , fps:139.83\n"
     ]
    }
   ],
   "source": [
    "benchmark_1min(\"/home/ubuntu/models/unet/trt-output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and benchmark FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the graph to TensorRT.\n",
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Running against TensorRT version 0.0.0\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/output/variables/variables\n",
      "INFO:tensorflow:Froze 38 variables.\n",
      "INFO:tensorflow:Converted 38 variables to const ops.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ubuntu/models/unet/trt-output-fp16/saved_model.pb\n",
      "Done. Converting the graph to TensorRT-FP16.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "print(\"Converting the graph to TensorRT.\")\n",
    "input_saved_model_dir = \"/home/ubuntu/models/unet/output\"\n",
    "output_saved_model_dir = \"/home/ubuntu/models/unet/trt-output-fp16/\"\n",
    "\n",
    "#If directory exists, delete it and let builder rebuild the TF model.\n",
    "if os.path.isdir(output_saved_model_dir):\n",
    "    print (output_saved_model_dir, \"exists already. Deleting the folder\")\n",
    "    shutil.rmtree(output_saved_model_dir)\n",
    "    \n",
    "converter = trt.TrtGraphConverter(\n",
    "    input_saved_model_dir=input_saved_model_dir,\n",
    "    precision_mode=\"FP16\",\n",
    "    maximum_cached_engines=100)\n",
    "\n",
    "_ = converter.convert()\n",
    "_ = converter.save(output_saved_model_dir)\n",
    "\n",
    "\n",
    "print(\"Done. Converting the graph to TensorRT-FP16.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the variables. As the frozen graph donot have any variables and it raises error while serving.\n",
    "!cp -pra /home/ubuntu/models/unet/output/variables/ /home/ubuntu/models/unet/trt-output-fp16/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/trt-output-fp16/variables/variables\n",
      "\n",
      "Model: /home/ubuntu/models/unet/trt-output-fp16/, Input shape: (1, 160, 160, 4) , Output shape: (1, 160, 160, 1) \n",
      "Completed Inference with one sample in 0.226 sec,\n"
     ]
    }
   ],
   "source": [
    "# Benchmark on one sample\n",
    "import time\n",
    "output_saved_model_dir = \"/home/ubuntu/models/unet/trt-output-fp16/\"\n",
    "output_tensor =  'PredictionMask/Sigmoid:0'\n",
    "input_tensor = 'MRImages:0'\n",
    "input_data = np.random.randint(0, 255, size=(1,160,160,4))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # First load the SavedModel into the session\n",
    "    tf.saved_model.loader.load(\n",
    "        sess, [tf.saved_model.tag_constants.SERVING],\n",
    "       output_saved_model_dir)\n",
    "    start_time = time.time()\n",
    "    output = sess.run([output_tensor], feed_dict={input_tensor: input_data})\n",
    "    delta = (time.time() - start_time)\n",
    "\n",
    "print(\"\\nModel: {}, Input shape: {} , Output shape: {} \\nCompleted Inference with one sample in {:.3f} sec,\"\n",
    "      .format(output_saved_model_dir, input_data.shape, output[0].shape, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/models/unet/trt-output-fp16/variables/variables\n",
      "23:54:43\n",
      "Running inference for 1 min, with BZ=1\n",
      "Model: /home/ubuntu/models/unet/trt-output-fp16/, Input shape: (1, 160, 160, 4)  \n",
      "Output Shape: (1, 160, 160, 1), \n",
      "average(sec):0.007 , average(msec):7.16 , fps:139.72\n"
     ]
    }
   ],
   "source": [
    "## Benchmark\n",
    "benchmark_1min(\"/home/ubuntu/models/unet/trt-output-fp16/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
